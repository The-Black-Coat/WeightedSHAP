{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429d6ca6",
   "metadata": {},
   "source": [
    "# Example: WeightedSHAP on the fraud dataset\n",
    "\n",
    "- In this notebook, we introduce weightedSHAP, which provides a generalized feature attribution method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f99822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pickle \n",
    "np.random.seed(2022)\n",
    "from analysis_utils import *\n",
    "\n",
    "sys.path.append('../weightedSHAP')\n",
    "import data, train, weightedSHAPEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157334be",
   "metadata": {},
   "source": [
    "## Load data\n",
    "- We use the fraud dataset (https://www.openml.org/search?type=data&status=active&id=42397).\n",
    "- A function `data.load_data` will load the `train`, `val`, `est`, and `test` datasets. \n",
    " - `train`: to train a model to explain\n",
    " - `val`: to optimize hyperparameters\n",
    " - `est`: to estimate coalition functions\n",
    " - `test`: to evaluate the quality of feature attributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f9d991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Load a dataset\n",
      "------------------------------\n",
      "--------------------------------------------------\n",
      "Fraud Detection\n",
      "--------------------------------------------------\n",
      "------------------------------\n",
      "Before adding noise\n",
      "Shape of X_train, X_val, X_est, X_test: (13310, 30), (1902, 30), (1902, 30), (1902, 30)\n",
      "------------------------------\n",
      "Rho: 0.0388\n",
      "After adding noise\n",
      "Shape of X_train, X_val, X_est, X_test: (13310, 90), (1902, 90), (1902, 90), (1902, 90)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "problem='classification' \n",
    "dataset='fraud'\n",
    "ML_model='boosting' \n",
    "(X_train, y_train), (X_val, y_val), (X_est, y_est), (X_test, y_test)=data.load_data(problem, dataset)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d203fb7",
   "metadata": {},
   "source": [
    "## Train a model to explain\n",
    " - This step is a typical routine in machine learning. Given training and validation datasets, we train a model. Our goal is to interpret this model by looking a particular prediction (i.e., a local attribution problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5c7be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train a model\n",
      "Train a model to explain: Boosting\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's binary_logloss: 0.646885\tvalid_0's binary_error: 0.0320715\n",
      "Elapsed time for training a model to explain: 0.54 seconds\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_to_explain=train.create_model_to_explain(X_train, y_train, X_val, y_val, problem, ML_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59c30c7",
   "metadata": {},
   "source": [
    "## Compute attributions and evaluate its performance\n",
    "- `weightedSHAPEngine.run_attribution_core` computes conditional expectation values $\\mathbb{E}[f(X) \\mid X_S = x_S]$ based on various weighted versions $\\phi_\\mathbf{w} (x_i) := \\sum_{j=1} ^{d} w_j \\Delta_{j}(x_i)$ of SHAP (Equation (5) of the paper). We consider a set $\\mathcal{W}$ which includes SHAP as well.\n",
    "- We store them in `exp_dict` which includes\n",
    " - `cond_pred_keep_absolute` (add features with large absolute values first)\n",
    " - `cond_pred_remove_absolute` (remove features with large absolute values first)\n",
    " - `pred_masking` (add features with large absolute values first and other featuers are masked with zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for training a surrogate model: 548.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 900, GR_stat: 1.007274776668469\n",
      "Total number of random sets: 1000, GR_stat: 1.0067500997071723\n",
      "Total number of random sets: 1100, GR_stat: 1.0066346271310442\n",
      "Total number of random sets: 1200, GR_stat: 1.0051719850889846\n",
      "Total number of random sets: 1300, GR_stat: 1.0059864735184305\n",
      "Total number of random sets: 1400, GR_stat: 1.0055448719292726\n",
      "Total number of random sets: 1500, GR_stat: 1.004794489707504\n",
      "MCI score: 8994, Therehosld: 8991\n",
      "We have seen 1600 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█                                                                                                     | 1/100 [00:46<1:17:24, 46.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 900, GR_stat: 1.007101462204402\n",
      "Total number of random sets: 1100, GR_stat: 1.0064411589724716\n",
      "Total number of random sets: 1300, GR_stat: 1.006964299222497\n",
      "Total number of random sets: 1400, GR_stat: 1.005469781048714\n",
      "Total number of random sets: 1500, GR_stat: 1.0050134224244465\n",
      "Total number of random sets: 1600, GR_stat: 1.007086689745792\n",
      "Total number of random sets: 1700, GR_stat: 1.0041482290171406\n",
      "MCI score: 8996, Therehosld: 8991\n",
      "We have seen 1800 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██                                                                                                    | 2/100 [01:39<1:22:03, 50.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 800, GR_stat: 1.0116016608201182\n",
      "Total number of random sets: 1000, GR_stat: 1.0084466638234113\n",
      "Total number of random sets: 1300, GR_stat: 1.0054095659241913\n",
      "Total number of random sets: 1400, GR_stat: 1.0049605126227612\n",
      "MCI score: 8997, Therehosld: 8991\n",
      "We have seen 1500 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|███                                                                                                   | 3/100 [02:22<1:16:04, 47.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1200, GR_stat: 1.0074184719588355\n",
      "Total number of random sets: 1300, GR_stat: 1.0048106818611944\n",
      "MCI score: 8994, Therehosld: 8991\n",
      "We have seen 1400 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|████                                                                                                  | 4/100 [03:03<1:11:00, 44.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1000, GR_stat: 1.0078974448414677\n",
      "Total number of random sets: 1100, GR_stat: 1.0047230983769468\n",
      "MCI score: 8995, Therehosld: 8991\n",
      "We have seen 1200 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█████                                                                                                 | 5/100 [03:37<1:04:27, 40.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 800, GR_stat: 1.00803748990048\n",
      "Total number of random sets: 1400, GR_stat: 1.0047963131950424\n",
      "MCI score: 8994, Therehosld: 8991\n",
      "We have seen 1500 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██████                                                                                                | 6/100 [04:20<1:05:10, 41.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1100, GR_stat: 1.0048207882301539\n",
      "MCI score: 8992, Therehosld: 8991\n",
      "We have seen 1200 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|███████▏                                                                                              | 7/100 [04:54<1:00:38, 39.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 900, GR_stat: 1.0085050163717155\n",
      "Total number of random sets: 1100, GR_stat: 1.0059396772246032\n",
      "Total number of random sets: 1200, GR_stat: 1.0052468816311353\n",
      "Total number of random sets: 1300, GR_stat: 1.0045262657958098\n",
      "MCI score: 8996, Therehosld: 8991\n",
      "We have seen 1400 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████████▏                                                                                             | 8/100 [05:34<1:00:29, 39.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1000, GR_stat: 1.0049833615234542\n",
      "MCI score: 8996, Therehosld: 8991\n",
      "We have seen 1100 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|█████████▎                                                                                              | 9/100 [06:05<55:55, 36.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1000, GR_stat: 1.0114249651285447\n",
      "Total number of random sets: 1100, GR_stat: 1.0083409315243033\n",
      "Total number of random sets: 1200, GR_stat: 1.0097357892547856\n",
      "Total number of random sets: 1300, GR_stat: 1.0113938536418166\n",
      "Total number of random sets: 1400, GR_stat: 1.006596022380817\n",
      "Total number of random sets: 1500, GR_stat: 1.0053342681570259\n",
      "Total number of random sets: 1600, GR_stat: 1.0071756715193805\n",
      "Total number of random sets: 1700, GR_stat: 1.0057508285644738\n",
      "Total number of random sets: 1800, GR_stat: 1.007268489549289\n",
      "Total number of random sets: 1900, GR_stat: 1.00816040509585\n",
      "Total number of random sets: 2000, GR_stat: 1.0081773674203363\n",
      "Total number of random sets: 2100, GR_stat: 1.0073145730361863\n",
      "Total number of random sets: 2200, GR_stat: 1.0058554864598057\n",
      "Total number of random sets: 2300, GR_stat: 1.0056892125418884\n",
      "Total number of random sets: 2400, GR_stat: 1.0079856988839428\n",
      "Total number of random sets: 2500, GR_stat: 1.0046990101346789\n",
      "MCI score: 8997, Therehosld: 8991\n",
      "We have seen 2600 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████████                                                                                           | 10/100 [07:22<1:13:49, 49.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 800, GR_stat: 1.0089416082261773\n",
      "Total number of random sets: 900, GR_stat: 1.0087905032361324\n",
      "Total number of random sets: 1000, GR_stat: 1.0088305513367513\n",
      "Total number of random sets: 1100, GR_stat: 1.0060630339840113\n",
      "Total number of random sets: 1200, GR_stat: 1.0054017502068644\n",
      "Total number of random sets: 1300, GR_stat: 1.0060885363871754\n",
      "Total number of random sets: 1500, GR_stat: 1.0046194897592617\n",
      "MCI score: 8993, Therehosld: 8991\n",
      "We have seen 1600 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|███████████                                                                                          | 11/100 [08:09<1:11:42, 48.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 700, GR_stat: 1.0077533436389683\n",
      "Total number of random sets: 1100, GR_stat: 1.0102683814519522\n",
      "Total number of random sets: 1200, GR_stat: 1.0066323879801786\n",
      "Total number of random sets: 1300, GR_stat: 1.007311530286495\n",
      "Total number of random sets: 1400, GR_stat: 1.0066018242839772\n",
      "Total number of random sets: 1500, GR_stat: 1.0043927120397595\n",
      "MCI score: 8992, Therehosld: 8991\n",
      "We have seen 1600 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████████████                                                                                         | 12/100 [08:55<1:10:03, 47.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1300, GR_stat: 1.00554749511505\n",
      "Total number of random sets: 1500, GR_stat: 1.0061762138723847\n",
      "Total number of random sets: 1600, GR_stat: 1.0043106287796406\n",
      "MCI score: 8997, Therehosld: 8991\n",
      "We have seen 1700 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████████▏                                                                                       | 13/100 [09:44<1:09:56, 48.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 700, GR_stat: 1.0100307989324342\n",
      "Total number of random sets: 1100, GR_stat: 1.0078306419865517\n",
      "Total number of random sets: 1200, GR_stat: 1.006167067828919\n",
      "Total number of random sets: 1300, GR_stat: 1.0068750390478802\n",
      "Total number of random sets: 1400, GR_stat: 1.005611606491501\n",
      "Total number of random sets: 1500, GR_stat: 1.0038825693075275\n",
      "MCI score: 8992, Therehosld: 8991\n",
      "We have seen 1600 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|██████████████▏                                                                                      | 14/100 [10:31<1:08:21, 47.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 800, GR_stat: 1.0123107947827377\n",
      "Total number of random sets: 1100, GR_stat: 1.0078513717435436\n",
      "Total number of random sets: 1300, GR_stat: 1.0066345386689064\n",
      "Total number of random sets: 1400, GR_stat: 1.008144488388134\n",
      "Total number of random sets: 1500, GR_stat: 1.0063177837627029\n",
      "Total number of random sets: 1600, GR_stat: 1.0084877288255083\n",
      "Total number of random sets: 1700, GR_stat: 1.0066976573876958\n",
      "Total number of random sets: 1800, GR_stat: 1.003335935696763\n",
      "MCI score: 8996, Therehosld: 8991\n",
      "We have seen 1900 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████████▏                                                                                     | 15/100 [11:26<1:10:56, 50.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1300, GR_stat: 1.0043011174758965\n",
      "MCI score: 8994, Therehosld: 8991\n",
      "We have seen 1400 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████████▏                                                                                    | 16/100 [12:07<1:06:02, 47.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 800, GR_stat: 1.0088814992608206\n",
      "Total number of random sets: 900, GR_stat: 1.0073084019020526\n",
      "Total number of random sets: 1100, GR_stat: 1.0044221967501579\n",
      "MCI score: 8993, Therehosld: 8991\n",
      "We have seen 1200 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████████▌                                                                                     | 17/100 [12:41<59:52, 43.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 800, GR_stat: 1.0062361228450658\n",
      "Total number of random sets: 900, GR_stat: 1.0083900385561306\n",
      "Total number of random sets: 1000, GR_stat: 1.0089888084853407\n",
      "Total number of random sets: 1100, GR_stat: 1.0074111343348238\n",
      "Total number of random sets: 1200, GR_stat: 1.006269787077985\n",
      "Total number of random sets: 1300, GR_stat: 1.0069165929138328\n",
      "Total number of random sets: 1600, GR_stat: 1.0037205579364952\n",
      "MCI score: 8995, Therehosld: 8991\n",
      "We have seen 1700 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████████▏                                                                                  | 18/100 [13:30<1:01:38, 45.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1100, GR_stat: 1.005722286866246\n",
      "Total number of random sets: 1200, GR_stat: 1.0053898359886089\n",
      "Total number of random sets: 1300, GR_stat: 1.0047727429787403\n",
      "MCI score: 8996, Therehosld: 8991\n",
      "We have seen 1400 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████████▌                                                                                   | 19/100 [14:11<58:58, 43.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1100, GR_stat: 1.0058654774879898\n",
      "Total number of random sets: 1200, GR_stat: 1.0084477111199148\n",
      "Total number of random sets: 1300, GR_stat: 1.003966253552515\n",
      "MCI score: 8995, Therehosld: 8991\n",
      "We have seen 1400 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████████▌                                                                                  | 20/100 [14:51<56:52, 42.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 900, GR_stat: 1.0089472226669236\n",
      "Total number of random sets: 1100, GR_stat: 1.00561813763626\n",
      "Total number of random sets: 1200, GR_stat: 1.0059517127770687\n",
      "Total number of random sets: 1300, GR_stat: 1.0068125429660706\n",
      "Total number of random sets: 1500, GR_stat: 1.0074275173984415\n",
      "Total number of random sets: 1600, GR_stat: 1.0045087587742487\n",
      "MCI score: 8995, Therehosld: 8991\n",
      "We have seen 1700 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████████▋                                                                                 | 21/100 [15:40<58:47, 44.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 900, GR_stat: 1.0075693790466647\n",
      "Total number of random sets: 1000, GR_stat: 1.0069168787142042\n",
      "Total number of random sets: 1100, GR_stat: 1.0082297666456115\n",
      "Total number of random sets: 1200, GR_stat: 1.0057384748994613\n",
      "Total number of random sets: 1300, GR_stat: 1.0053133340975076\n",
      "Total number of random sets: 1500, GR_stat: 1.0048531394385691\n",
      "MCI score: 8994, Therehosld: 8991\n",
      "We have seen 1600 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████████▋                                                                                | 22/100 [16:27<58:43, 45.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1100, GR_stat: 1.0052083533227063\n",
      "Total number of random sets: 1200, GR_stat: 1.0057265505847763\n",
      "Total number of random sets: 1400, GR_stat: 1.0046734385466016\n",
      "MCI score: 8994, Therehosld: 8991\n",
      "We have seen 1500 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|███████████████████████▋                                                                               | 23/100 [17:10<57:14, 44.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1000, GR_stat: 1.009601660423236\n",
      "Total number of random sets: 1200, GR_stat: 1.0065318211282788\n",
      "Total number of random sets: 1300, GR_stat: 1.0076766851554309\n",
      "Total number of random sets: 1400, GR_stat: 1.005283747032439\n",
      "Total number of random sets: 1500, GR_stat: 1.0051048593222507\n",
      "Total number of random sets: 1600, GR_stat: 1.0052170922771897\n",
      "Total number of random sets: 1700, GR_stat: 1.0055036067193428\n",
      "Total number of random sets: 1800, GR_stat: 1.0041734170961198\n",
      "MCI score: 8998, Therehosld: 8991\n",
      "We have seen 1900 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|████████████████████████▏                                                                            | 24/100 [18:06<1:00:40, 47.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1100, GR_stat: 1.0075444546265124\n",
      "Total number of random sets: 1300, GR_stat: 1.0061850911746568\n",
      "Total number of random sets: 1500, GR_stat: 1.0072602117776293\n",
      "Total number of random sets: 1700, GR_stat: 1.0052035439342615\n",
      "Total number of random sets: 1800, GR_stat: 1.0045037523177187\n",
      "MCI score: 8994, Therehosld: 8991\n",
      "We have seen 1900 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████████████████▎                                                                           | 25/100 [19:01<1:02:43, 50.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1200, GR_stat: 1.004601183953125\n",
      "MCI score: 8995, Therehosld: 8991\n",
      "We have seen 1300 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██████████████████████████▊                                                                            | 26/100 [19:39<57:09, 46.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 900, GR_stat: 1.0075752224795687\n",
      "Total number of random sets: 1000, GR_stat: 1.0085860968952842\n",
      "Total number of random sets: 1100, GR_stat: 1.005364231975834\n",
      "Total number of random sets: 1400, GR_stat: 1.0067690051336717\n",
      "Total number of random sets: 1500, GR_stat: 1.0069489324753278\n",
      "Total number of random sets: 1600, GR_stat: 1.0045403287313615\n",
      "MCI score: 8992, Therehosld: 8991\n",
      "We have seen 1700 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████████████████████▊                                                                           | 27/100 [20:28<57:37, 47.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 900, GR_stat: 1.010033082242018\n",
      "Total number of random sets: 1100, GR_stat: 1.0070645976368044\n",
      "Total number of random sets: 1500, GR_stat: 1.0061879406524161\n",
      "Total number of random sets: 1600, GR_stat: 1.0041084704532455\n",
      "MCI score: 8994, Therehosld: 8991\n",
      "We have seen 1700 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|████████████████████████████▊                                                                          | 28/100 [21:18<57:40, 48.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of random sets: 1000, GR_stat: 1.0066044763084026\n",
      "Total number of random sets: 1100, GR_stat: 1.00467821067648\n",
      "MCI score: 8997, Therehosld: 8991\n",
      "We have seen 1200 random subsets for each feature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|█████████████████████████████▊                                                                         | 29/100 [21:52<52:02, 43.98s/it]"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('fraud_example.pickle'):\n",
    "    # Train a surrogate model and generate a coalition function\n",
    "    # To efficiently estimate a conditional coalition function, we train a surrogate model. \n",
    "    conditional_extension=train.generate_coalition_function(model_to_explain, X_train, X_est, problem, ML_model)\n",
    "    \n",
    "    # With a surrogate model, we compute conditional expectations\n",
    "    exp_dict=weightedSHAPEngine.run_attribution_core(problem, ML_model,\n",
    "                                                     model_to_explain, conditional_extension,\n",
    "                                                     X_train, y_train,\n",
    "                                                     X_val, y_val, \n",
    "                                                     X_test, y_test)\n",
    "\n",
    "    with open('fraud_example.pickle', 'wb') as handle:\n",
    "        pickle.dump(exp_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open('fraud_example.pickle', 'rb') as handle:\n",
    "        exp_dict = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea55d5e",
   "metadata": {},
   "source": [
    "## WeightedSHAP and Prediction recovery error curve \n",
    " - We obtain weightedSHAP (Equation (6) of the paper)\n",
    " \\begin{align*}\n",
    "    \\phi_{\\mathrm{WeightedSHAP}}(\\mathcal{T}, \\mathcal{W}) := \\phi_{\\mathbf{w}^* (\\mathcal{T}, \\mathcal{W})},\n",
    " \\end{align*} \n",
    " where $\\mathbf{w}^* (\\mathcal{T}, \\mathcal{W}) := \\mathrm{argmax}_{\\mathbf{w} \\in \\mathcal{W}} \\mathcal{T} (\\phi_{\\mathbf{w}})$.\n",
    " - A default implementation for $\\mathcal{T}$ includes the negative area under the prediction recovery error curve (AUP, Equation (4) of the paper) with `cond_pred_keep_absolute`. Note that `exp_dict` contains `remove_abolute` and `masking` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.array(exp_dict['true_list'])\n",
    "pred_list=np.array(exp_dict['pred_list'])\n",
    "cond_pred_keep_absolute=np.array(exp_dict['cond_pred_keep_absolute'])\n",
    "# Find a optimal weight and construct WeightedSHAP\n",
    "optimal_ind_keep_absolute_list=find_optimal_list(cond_pred_keep_absolute, pred_list) \n",
    "\n",
    "# {13:MCI, 6:SHAP}\n",
    "cond_pred_keep_absolute_short=np.array((cond_pred_keep_absolute[:,13,:],\n",
    "                                    cond_pred_keep_absolute[:,6,:],\n",
    "                                    cond_pred_keep_absolute[np.arange(len(optimal_ind_keep_absolute_list)),\n",
    "                                                            optimal_ind_keep_absolute_list,:])).transpose((1,0,2))\n",
    "recovery_curve_keep_absolute=np.mean(np.abs(cond_pred_keep_absolute_short - pred_list.reshape(-1,1,1)), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5ecf7a",
   "metadata": {},
   "source": [
    " - The recovery error curves will become more smooth by increasing the number of test samples. It comes with more computational expenses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features=len(recovery_curve_keep_absolute[0])\n",
    "n_display_features=int(n_features*0.6)\n",
    "\n",
    "plt.plot(recovery_curve_keep_absolute[0][max(1,int(n_features*0.075)):n_display_features],\n",
    "         label='MCI', color='blue', linewidth=2, alpha=0.6)\n",
    "plt.plot(recovery_curve_keep_absolute[1][max(1,int(n_features*0.075)):n_display_features],\n",
    "         label='Shapley', color='green', linewidth=2, alpha=0.6)\n",
    "plt.plot(recovery_curve_keep_absolute[2][max(1,int(n_features*0.075)):n_display_features],\n",
    "         label='WeightedSHAP', color='red', linewidth=2, alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "xlabel_text='Number of features added' \n",
    "plt.title(f'Prediction recovery error curve, Dataset: fraud \\n the lower, the better', fontsize=15)\n",
    "plt.xticks(np.arange(n_features)[max(1,int(n_features*0.075)):n_display_features][::n_display_features//6],\n",
    "               np.arange(n_features)[max(1,int(n_features*0.075)):n_display_features][::n_display_features//6])\n",
    "plt.xlabel(xlabel_text, fontsize=15)\n",
    "plt.ylabel(r'$|f(x)-\\mathbb{E}[f(X) \\mid X_S = x_S]|$', fontsize=15)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb86ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f6b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f644caf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
